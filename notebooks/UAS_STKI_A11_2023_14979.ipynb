{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import File Yang Dibutuhkan"
      ],
      "metadata": {
        "id": "sNsRmn2mEsWY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Hi_dojy1CR10",
        "outputId": "d9ea8754-d7ba-4108-99c6-5d91496170be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b31b081d-5f8a-4ae6-aed4-fddb97c82c77\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b31b081d-5f8a-4ae6-aed4-fddb97c82c77\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving stki-uas-A11.2023.14979.zip to stki-uas-A11.2023.14979.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile(\"stki-uas-A11.2023.14979.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"project\")\n",
        "\n",
        "os.listdir(\"project\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-HJufvyCo5N",
        "outputId": "851cfe53-4f75-41e8-88a9-a0a3289f0be1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stki-uas-A11.2023.14979']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UAS Sistem Temu Kembali Informasi\n",
        "\n",
        "Nama : Suluh Yoga Pratama  \n",
        "NIM  : A11.2023.14979  \n",
        "\n",
        "Notebook ini berisi implementasi dan pengujian:\n",
        "- Preprocessing\n",
        "- Boolean Information Retrieval\n",
        "- Vector Space Model (TF-IDF)\n",
        "- Clustering Dokumen\n",
        "- Text Summarization"
      ],
      "metadata": {
        "id": "LPjhwqgWDJH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Set Directory & Setup Library"
      ],
      "metadata": {
        "id": "tglgz1YAE3Pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/project/stki-uas-A11.2023.14979\")"
      ],
      "metadata": {
        "id": "PkF5TQShDHPK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6e5H9nMEKhu",
        "outputId": "6e514e3e-b34f-4818-87e4-edaafc7a35f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit (from -r requirements.txt (line 1))\n",
            "  Downloading streamlit-1.52.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (3.9.1)\n",
            "Collecting sastrawi (from -r requirements.txt (line 3))\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (6.2.4)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (8.3.1)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit->-r requirements.txt (line 1))\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 1)) (6.5.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 2)) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 5)) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->-r requirements.txt (line 1)) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->-r requirements.txt (line 1)) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 1)) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 1)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 1)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 1)) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 1)) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->-r requirements.txt (line 1)) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->-r requirements.txt (line 1)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->-r requirements.txt (line 1)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->-r requirements.txt (line 1)) (0.30.0)\n",
            "Downloading streamlit-1.52.2-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m133.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sastrawi, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 sastrawi-1.0.1 streamlit-1.52.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R_ZzMe5EWWG",
        "outputId": "7cc36496-f5bd-431e-bd39-50fbe5556f48"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import Modul Project"
      ],
      "metadata": {
        "id": "HIymZLzrFBRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(os.getcwd())"
      ],
      "metadata": {
        "id": "Odc3t7h3DNP_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.preprocess import preprocess_text\n",
        "from src.search import search_boolean, search_vector\n",
        "from src.clustering import clustering_kmeans\n",
        "from src.summarization import summarize_document"
      ],
      "metadata": {
        "id": "87JkEYJyDRTB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preprocessing"
      ],
      "metadata": {
        "id": "1b7CUzp6FIIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"\n",
        "Ekonomi digital berkembang pesat di Indonesia.\n",
        "Transformasi teknologi mendorong pertumbuhan UMKM nasional.\n",
        "\"\"\"\n",
        "\n",
        "tokens = preprocess_text(sample_text)\n",
        "\n",
        "print(\"HASIL PREPROCESSING\")\n",
        "print(\"-\"*40)\n",
        "print(\"Jumlah token:\", len(tokens))\n",
        "print(\"Token (contoh):\")\n",
        "print(\", \".join(tokens[:15]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqOMbc_-EbPC",
        "outputId": "1fbb90ec-160a-49fc-d047-a6cc7be33f47"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HASIL PREPROCESSING\n",
            "----------------------------------------\n",
            "Jumlah token: 11\n",
            "Token (contoh):\n",
            "ekonomi, digital, kembang, pesat, indonesia, transformasi, teknologi, dorong, tumbuh, umkm, nasional\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Boolean IR"
      ],
      "metadata": {
        "id": "DmezBs55FLpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    \"ekonomi\",\n",
        "    \"ekonomi AND digital\",\n",
        "    \"hukum OR sosial\",\n",
        "    \"NOT kesehatan\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    print(\"\\nQUERY:\", q)\n",
        "    print(\"-\"*40)\n",
        "\n",
        "    results = search_boolean(q)\n",
        "\n",
        "    if not results:\n",
        "        print(\"Tidak ada dokumen ditemukan.\")\n",
        "    else:\n",
        "        for r in results[:10]:\n",
        "            print(\"‚Ä¢\", r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFTkDCCBEdSx",
        "outputId": "25764c43-19f9-46f4-80b8-994c17a9c274"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "QUERY: ekonomi\n",
            "----------------------------------------\n",
            "‚Ä¢ ekonomi_bank_mandiri_prediksi_ekonomi_indonesia_tumbuh_44__003.txt\n",
            "‚Ä¢ ekonomi_di_forum_internasional_sri_mulyani_cerita_ekonomi__009.txt\n",
            "‚Ä¢ ekonomi_ekonomi_bakal_pulih_usai_penemuan_vaksin_covid19_b_008.txt\n",
            "‚Ä¢ ekonomi_ekonomi_ri_bakal_membaik_intip_3_sektor_saham_pili_004.txt\n",
            "‚Ä¢ ekonomi_gubernur_bi_perry_warjiyo_ungkap_3_cara_akselerasi_006.txt\n",
            "‚Ä¢ ekonomi_jokowi_komitmen_lanjutkan_program_bansos_dan_keseh_007.txt\n",
            "‚Ä¢ ekonomi_menko_airlangga_yakin_ekonomi_indonesia_tumbuh_55__001.txt\n",
            "‚Ä¢ ekonomi_pelabuhan_patimban_bakal_tingkatkan_kesejahteraan__010.txt\n",
            "‚Ä¢ ekonomi_realisasi_investasi_asing_bakal_bantu_pertumbuhan__002.txt\n",
            "‚Ä¢ ekonomi_vaksinasi_covid19_jadi_salah_satu_strategi_pemerin_005.txt\n",
            "\n",
            "QUERY: ekonomi AND digital\n",
            "----------------------------------------\n",
            "‚Ä¢ ekonomi_bank_mandiri_prediksi_ekonomi_indonesia_tumbuh_44__003.txt\n",
            "‚Ä¢ ekonomi_realisasi_investasi_asing_bakal_bantu_pertumbuhan__002.txt\n",
            "‚Ä¢ ekonomi_vaksinasi_covid19_jadi_salah_satu_strategi_pemerin_005.txt\n",
            "\n",
            "QUERY: hukum OR sosial\n",
            "----------------------------------------\n",
            "‚Ä¢ ekonomi_bank_mandiri_prediksi_ekonomi_indonesia_tumbuh_44__003.txt\n",
            "‚Ä¢ ekonomi_gubernur_bi_perry_warjiyo_ungkap_3_cara_akselerasi_006.txt\n",
            "‚Ä¢ ekonomi_jokowi_komitmen_lanjutkan_program_bansos_dan_keseh_007.txt\n",
            "‚Ä¢ hukum_arab_saudi_rilis_hukum_bagi_pelaku_pelecehan_seksu_030.txt\n",
            "‚Ä¢ hukum_dpr_as_seorang_kader_partai_republik_penyebar_teor_021.txt\n",
            "‚Ä¢ hukum_instagram_sammy_simorangkir_diretas_istri_sigap_am_026.txt\n",
            "‚Ä¢ hukum_kasus_siswi_nonmuslim_disuruh_berjilbab_kuasa_huku_025.txt\n",
            "‚Ä¢ hukum_pakar_hukum_sebut_penyitaan_aset_terkait_tppu_jang_024.txt\n",
            "‚Ä¢ hukum_pakar_penegak_hukum_perlu_hatihati_sita_aset_terka_028.txt\n",
            "‚Ä¢ hukum_perkara_hukum_status_kewarganegaraan_bupati_terpil_022.txt\n",
            "\n",
            "QUERY: NOT kesehatan\n",
            "----------------------------------------\n",
            "‚Ä¢ ekonomi_bank_mandiri_prediksi_ekonomi_indonesia_tumbuh_44__003.txt\n",
            "‚Ä¢ ekonomi_di_forum_internasional_sri_mulyani_cerita_ekonomi__009.txt\n",
            "‚Ä¢ ekonomi_ekonomi_bakal_pulih_usai_penemuan_vaksin_covid19_b_008.txt\n",
            "‚Ä¢ ekonomi_ekonomi_ri_bakal_membaik_intip_3_sektor_saham_pili_004.txt\n",
            "‚Ä¢ ekonomi_gubernur_bi_perry_warjiyo_ungkap_3_cara_akselerasi_006.txt\n",
            "‚Ä¢ ekonomi_jokowi_komitmen_lanjutkan_program_bansos_dan_keseh_007.txt\n",
            "‚Ä¢ ekonomi_menko_airlangga_yakin_ekonomi_indonesia_tumbuh_55__001.txt\n",
            "‚Ä¢ ekonomi_pelabuhan_patimban_bakal_tingkatkan_kesejahteraan__010.txt\n",
            "‚Ä¢ ekonomi_realisasi_investasi_asing_bakal_bantu_pertumbuhan__002.txt\n",
            "‚Ä¢ ekonomi_vaksinasi_covid19_jadi_salah_satu_strategi_pemerin_005.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Vector Space Model (VSM)"
      ],
      "metadata": {
        "id": "msL0LyhTFSIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"ekonomi teknologi digital\"\n",
        "\n",
        "results = search_vector(query)\n",
        "\n",
        "print(\"HASIL VECTOR SPACE MODEL\")\n",
        "print(\"-\"*40)\n",
        "\n",
        "for i, (doc, score) in enumerate(results, start=1):\n",
        "    print(f\"{i}. {doc}\")\n",
        "    print(f\"   Skor Similaritas: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th4yGa08FOSt",
        "outputId": "ac682129-8535-4f9a-8b80-a945bf2588c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HASIL VECTOR SPACE MODEL\n",
            "----------------------------------------\n",
            "1. teknologi_ketika_syariat_islam_berpadu_dengan_teknologi_016.txt\n",
            "   Skor Similaritas: 0.2591\n",
            "2. ekonomi_vaksinasi_covid19_jadi_salah_satu_strategi_pemerin_005.txt\n",
            "   Skor Similaritas: 0.2520\n",
            "3. teknologi_lewat_teknologi_pasarpolis_manfaatkan_peluang_gap__015.txt\n",
            "   Skor Similaritas: 0.2292\n",
            "4. ekonomi_realisasi_investasi_asing_bakal_bantu_pertumbuhan__002.txt\n",
            "   Skor Similaritas: 0.1916\n",
            "5. ekonomi_jokowi_komitmen_lanjutkan_program_bansos_dan_keseh_007.txt\n",
            "   Skor Similaritas: 0.1894\n",
            "6. ekonomi_di_forum_internasional_sri_mulyani_cerita_ekonomi__009.txt\n",
            "   Skor Similaritas: 0.1749\n",
            "7. sosial_1387_hoaks_beredar_di_media_sosial_hngga_26_januar_036.txt\n",
            "   Skor Similaritas: 0.1723\n",
            "8. ekonomi_bank_mandiri_prediksi_ekonomi_indonesia_tumbuh_44__003.txt\n",
            "   Skor Similaritas: 0.1710\n",
            "9. ekonomi_gubernur_bi_perry_warjiyo_ungkap_3_cara_akselerasi_006.txt\n",
            "   Skor Similaritas: 0.1682\n",
            "10. ekonomi_ekonomi_bakal_pulih_usai_penemuan_vaksin_covid19_b_008.txt\n",
            "   Skor Similaritas: 0.1654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Clustering"
      ],
      "metadata": {
        "id": "U2YGz2BLFZKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clusters = clustering_kmeans(\"data/processed\", k=5)\n",
        "\n",
        "print(\"HASIL CLUSTERING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for label in sorted(clusters.keys()):\n",
        "    docs = clusters[label]\n",
        "    print(f\"\\nCluster {label} ({len(docs)} dokumen)\")\n",
        "    print(\"-\"*40)\n",
        "    for d in docs:\n",
        "        print(\"‚Ä¢\", d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPO7HnAKFWBF",
        "outputId": "d6f649e1-77b7-4dcc-d1b6-a9fd350a1fb2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HASIL CLUSTERING\n",
            "==================================================\n",
            "\n",
            "Cluster 0 (7 dokumen)\n",
            "----------------------------------------\n",
            "‚Ä¢ hukum_pakar_hukum_sebut_penyitaan_aset_terkait_tppu_jang_024.txt\n",
            "‚Ä¢ hukum_pakar_penegak_hukum_perlu_hatihati_sita_aset_terka_028.txt\n",
            "‚Ä¢ ekonomi_ekonomi_ri_bakal_membaik_intip_3_sektor_saham_pili_004.txt\n",
            "‚Ä¢ sosial_harga_telur_ayam_anjlok_parah_peternak_salahkan_pe_033.txt\n",
            "‚Ä¢ teknologi_ride_vision_kembangkan_keselamatan_sepeda_motor_018.txt\n",
            "‚Ä¢ hukum_instagram_sammy_simorangkir_diretas_istri_sigap_am_026.txt\n",
            "‚Ä¢ ekonomi_gubernur_bi_perry_warjiyo_ungkap_3_cara_akselerasi_006.txt\n",
            "\n",
            "Cluster 1 (7 dokumen)\n",
            "----------------------------------------\n",
            "‚Ä¢ sosial_ikut_challenge_di_media_sosial_sambil_jaga_kesehat_032.txt\n",
            "‚Ä¢ kesehatan_ppkm_bisa_berjalan_efektif_bila_masyarakat_patuh_p_049.txt\n",
            "‚Ä¢ hukum_kasus_siswi_nonmuslim_disuruh_berjilbab_kuasa_huku_025.txt\n",
            "‚Ä¢ sosial_belasan_pelanggar_tertib_masker_di_cilandak_disank_038.txt\n",
            "‚Ä¢ teknologi_4_tren_teknologi_jaringan_menurut_aruba_pada_2021_013.txt\n",
            "‚Ä¢ sosial_faktor_sosial_dan_struktural_pengaruhi_kesenjangan_040.txt\n",
            "‚Ä¢ sosial_anakanak_berbohong_soal_usia_saat_membuat_akun_med_034.txt\n",
            "\n",
            "Cluster 2 (11 dokumen)\n",
            "----------------------------------------\n",
            "‚Ä¢ kesehatan_jokowi_ingin_program_vaksinasi_covid19_untuk_tenag_047.txt\n",
            "‚Ä¢ kesehatan_potret_masyarakat_masih_abai_protokol_kesehatan_di_044.txt\n",
            "‚Ä¢ kesehatan_8150_tenaga_kesehatan_di_malang_tuntaskan_vaksinas_043.txt\n",
            "‚Ä¢ kesehatan_penjelasan_menkes_soal_rencana_pemangkasan_insenti_048.txt\n",
            "‚Ä¢ hukum_seorang_tersangka_korupsi_hotel_kuansing_lepas_dar_023.txt\n",
            "‚Ä¢ sosial_penyaluran_bantuan_sosial_tuna_terus_digelontorkan_031.txt\n",
            "‚Ä¢ kesehatan_10_daerah_jatim_tuntas_100_persen_vaksinasi_tenaga_041.txt\n",
            "‚Ä¢ kesehatan_10809_tenaga_kesehatan_di_bangka_belitung_divaksin_045.txt\n",
            "‚Ä¢ kesehatan_hari_ini_jabar_gelar_vaksinasi_covid19_masif_untuk_050.txt\n",
            "‚Ä¢ kesehatan_pembatasan_aktivitas_masyarakat_bandara_sams_sepin_042.txt\n",
            "‚Ä¢ teknologi_roket_bertenaga_nuklir_bisa_terbangkan_astronout_k_012.txt\n",
            "\n",
            "Cluster 3 (19 dokumen)\n",
            "----------------------------------------\n",
            "‚Ä¢ ekonomi_di_forum_internasional_sri_mulyani_cerita_ekonomi__009.txt\n",
            "‚Ä¢ hukum_perkara_hukum_status_kewarganegaraan_bupati_terpil_022.txt\n",
            "‚Ä¢ teknologi_mobil_listrik_cina_hadirkan_teknologi_pengecasan_n_019.txt\n",
            "‚Ä¢ ekonomi_bank_mandiri_prediksi_ekonomi_indonesia_tumbuh_44__003.txt\n",
            "‚Ä¢ ekonomi_realisasi_investasi_asing_bakal_bantu_pertumbuhan__002.txt\n",
            "‚Ä¢ teknologi_mahasiswa_kkn_upgris_ajak_masyarakat_melek_teknolo_011.txt\n",
            "‚Ä¢ hukum_pkb_bersyukur_ruu_pks_masuk_prolegnas_prioritas_20_029.txt\n",
            "‚Ä¢ hukum_dpr_as_seorang_kader_partai_republik_penyebar_teor_021.txt\n",
            "‚Ä¢ ekonomi_ekonomi_bakal_pulih_usai_penemuan_vaksin_covid19_b_008.txt\n",
            "‚Ä¢ teknologi_lewat_teknologi_pasarpolis_manfaatkan_peluang_gap__015.txt\n",
            "‚Ä¢ hukum_thailand_akan_hukum_penyebar_hoaks_tentang_vaksin__027.txt\n",
            "‚Ä¢ sosial_sandiaga_hadirkan_perlindungan_sosial_dan_stimulus_035.txt\n",
            "‚Ä¢ ekonomi_menko_airlangga_yakin_ekonomi_indonesia_tumbuh_55__001.txt\n",
            "‚Ä¢ ekonomi_vaksinasi_covid19_jadi_salah_satu_strategi_pemerin_005.txt\n",
            "‚Ä¢ sosial_implementasi_vaksin_covid19_mandiri_berpotensi_pic_039.txt\n",
            "‚Ä¢ ekonomi_jokowi_komitmen_lanjutkan_program_bansos_dan_keseh_007.txt\n",
            "‚Ä¢ kesehatan_pemprov_dki_akan_bahas_denda_progresif_pelanggar_p_046.txt\n",
            "‚Ä¢ teknologi_teknologi_terdepan_bakalan_hadir_di_the_epic_by_sa_014.txt\n",
            "‚Ä¢ ekonomi_pelabuhan_patimban_bakal_tingkatkan_kesejahteraan__010.txt\n",
            "\n",
            "Cluster 4 (6 dokumen)\n",
            "----------------------------------------\n",
            "‚Ä¢ sosial_1387_hoaks_beredar_di_media_sosial_hngga_26_januar_036.txt\n",
            "‚Ä¢ teknologi_mobil_listrik_cadillac_celestiq_punya_teknologi_ke_020.txt\n",
            "‚Ä¢ teknologi_ketika_syariat_islam_berpadu_dengan_teknologi_016.txt\n",
            "‚Ä¢ hukum_arab_saudi_rilis_hukum_bagi_pelaku_pelecehan_seksu_030.txt\n",
            "‚Ä¢ sosial_ada_1387_hoaks_tentang_covid19_di_media_sosial_hin_037.txt\n",
            "‚Ä¢ teknologi_ceo_apple_umbar_perusahaan_teknologi_pemasok_hoaks_017.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Text Summarization"
      ],
      "metadata": {
        "id": "BPAxeMNiFe6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "raw_folder = \"data/raw\"\n",
        "files = [f for f in os.listdir(raw_folder) if f.endswith(\".txt\")]\n",
        "\n",
        "file_path = os.path.join(raw_folder, files[0])\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "summary = summarize_document(raw_text)\n",
        "\n",
        "print(\"RINGKASAN DOKUMEN\")\n",
        "print(\"=\"*50)\n",
        "print(\"Dokumen:\", files[0])\n",
        "print(\"-\"*40)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GI-lyMbFb7u",
        "outputId": "849c39da-e6db-497d-c129-81aa6596bd10"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RINGKASAN DOKUMEN\n",
            "==================================================\n",
            "Dokumen: sosial_1387_hoaks_beredar_di_media_sosial_hngga_26_januar_036.txt\n",
            "----------------------------------------\n",
            "üìå Judul:\n",
            "1.387 Hoaks Beredar di Media Sosial Hngga 26 Januari 2021\n",
            "\n",
            "üìù Ringkasan Artikel:\n",
            "Kominfo pun menandainya sebagai hoaks,\" tutur Semuel. Hoaks sebanyak itu tercatat sejak Maret 2020 hingga 26 Januari 2021.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Evaluasi Information Retrieval (Precision & Recall)"
      ],
      "metadata": {
        "id": "YhVmo8Jdlz3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.search import search_boolean, search_vector\n",
        "from src.eval import precision_recall\n",
        "\n",
        "query = \"ekonomi\"\n",
        "\n",
        "# Ground truth manual (berdasarkan kategori dataset)\n",
        "gold_relevant = {\n",
        "    \"ekonomi_bank_mandiri_prediksi_ekonomi_indonesia_tumbuh_44__003.txt\",\n",
        "    \"ekonomi_di_forum_internasional_sri_mulyani_cerita_ekonomi__009.txt\",\n",
        "    \"ekonomi_ekonomi_bakal_pulih_usai_penemuan_vaksin_covid19_b_008.txt\"\n",
        "}\n",
        "\n",
        "print(\"EVALUASI INFORMATION RETRIEVAL\")\n",
        "print(\"=\"*60)\n",
        "print(\"Query:\", query)\n",
        "print(\"Ground Truth:\", gold_relevant)\n",
        "\n",
        "# Boolean IR\n",
        "boolean_result = search_boolean(query)\n",
        "\n",
        "p, r, tp, fp, fn = precision_recall(boolean_result, gold_relevant)\n",
        "\n",
        "print(\"\\n--- Boolean IR ---\")\n",
        "print(f\"Precision : {p:.3f}\")\n",
        "print(f\"Recall    : {r:.3f}\")\n",
        "print(f\"TP={tp}, FP={fp}, FN={fn}\")\n",
        "\n",
        "# Vector Space Model\n",
        "vsm_result = [doc for doc, _ in search_vector(query)]\n",
        "\n",
        "p, r, tp, fp, fn = precision_recall(vsm_result, gold_relevant)\n",
        "\n",
        "print(\"\\n--- Vector Space Model ---\")\n",
        "print(f\"Precision : {p:.3f}\")\n",
        "print(f\"Recall    : {r:.3f}\")\n",
        "print(f\"TP={tp}, FP={fp}, FN={fn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJbyxugsl1qX",
        "outputId": "ec472d74-3e72-4e83-e21b-9acc65fe793f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVALUASI INFORMATION RETRIEVAL\n",
            "============================================================\n",
            "Query: ekonomi\n",
            "Ground Truth: {'ekonomi_ekonomi_bakal_pulih_usai_penemuan_vaksin_covid19_b_008.txt', 'ekonomi_di_forum_internasional_sri_mulyani_cerita_ekonomi__009.txt', 'ekonomi_bank_mandiri_prediksi_ekonomi_indonesia_tumbuh_44__003.txt'}\n",
            "\n",
            "--- Boolean IR ---\n",
            "Precision : 0.188\n",
            "Recall    : 1.000\n",
            "TP=3, FP=13, FN=0\n",
            "\n",
            "--- Vector Space Model ---\n",
            "Precision : 0.300\n",
            "Recall    : 1.000\n",
            "TP=3, FP=7, FN=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Evaluasi Text Summarization (ROUGE-1)"
      ],
      "metadata": {
        "id": "n3btieTBmQiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from src.summarization import summarize_text\n",
        "\n",
        "def rouge_1(system_summary, reference_summary):\n",
        "    sys_tokens = set(word_tokenize(system_summary.lower()))\n",
        "    ref_tokens = set(word_tokenize(reference_summary.lower()))\n",
        "\n",
        "    overlap = sys_tokens & ref_tokens\n",
        "    precision = len(overlap) / len(sys_tokens) if sys_tokens else 0\n",
        "    recall = len(overlap) / len(ref_tokens) if ref_tokens else 0\n",
        "\n",
        "    return precision, recall\n",
        "\n",
        "text = \"\"\"\n",
        "Ekonomi digital berkembang pesat di Indonesia.\n",
        "Transformasi teknologi mendorong pertumbuhan UMKM.\n",
        "Namun, tantangan regulasi masih menjadi kendala utama.\n",
        "\"\"\"\n",
        "\n",
        "reference_summary = \"Ekonomi digital berkembang pesat dan mendorong UMKM.\"\n",
        "\n",
        "system_summary = summarize_text(text, max_sentences=1)\n",
        "\n",
        "p, r = rouge_1(system_summary, reference_summary)\n",
        "\n",
        "print(\"EVALUASI TEXT SUMMARIZATION (ROUGE-1)\")\n",
        "print(\"=\"*60)\n",
        "print(\"System Summary   :\", system_summary)\n",
        "print(\"Reference Summary:\", reference_summary)\n",
        "print(f\"Precision : {p:.3f}\")\n",
        "print(f\"Recall    : {r:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAD9IuHFmUP_",
        "outputId": "4fad11cd-f772-48ad-c099-78aa29918d05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVALUASI TEXT SUMMARIZATION (ROUGE-1)\n",
            "============================================================\n",
            "System Summary   : \n",
            "Ekonomi digital berkembang pesat di Indonesia.\n",
            "Reference Summary: Ekonomi digital berkembang pesat dan mendorong UMKM.\n",
            "Precision : 0.714\n",
            "Recall    : 0.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Analisis, Diskusi, dan Kesimpulan"
      ],
      "metadata": {
        "id": "fWTPEx-enZA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>Evaluasi Information Retrieval</b>\n",
        "\n",
        "Pengujian sistem temu kembali informasi dilakukan menggunakan satu query uji, yaitu \"ekonomi\", dengan tiga dokumen relevan yang ditentukan secara manual sebagai ground truth.\n",
        "\n",
        "# <b>Hasil evaluasi Boolean Information Retrieval menunjukkan:</b>\n",
        "\n",
        "Precision = 0.188\n",
        "\n",
        "Recall = 1.000\n",
        "\n",
        "True Positive (TP) = 3\n",
        "\n",
        "False Positive (FP) = 13\n",
        "\n",
        "False Negative (FN) = 0\n",
        "\n",
        "Nilai recall sebesar 1.000 menunjukkan bahwa seluruh dokumen relevan berhasil ditemukan oleh sistem. Namun, nilai precision yang rendah mengindikasikan bahwa sistem juga mengambil cukup banyak dokumen yang tidak relevan. Hal ini sesuai dengan karakteristik model Boolean yang hanya mempertimbangkan keberadaan kata kunci tanpa memperhitungkan tingkat relevansi dokumen.\n",
        "\n",
        "# <b>Hasil evaluasi Vector Space Model (TF-IDF) menunjukkan:</b>\n",
        "\n",
        "Precision = 0.300\n",
        "\n",
        "Recall = 1.000\n",
        "\n",
        "True Positive (TP) = 3\n",
        "\n",
        "False Positive (FP) = 7\n",
        "\n",
        "False Negative (FN) = 0\n",
        "\n",
        "Model Vector Space Model mampu mempertahankan nilai recall maksimal, sekaligus meningkatkan nilai precision dibandingkan Boolean IR. Hal ini menunjukkan bahwa pendekatan berbasis pembobotan TF-IDF dan cosine similarity lebih efektif dalam menyaring dokumen yang relevan.\n",
        "\n",
        "# <b>Evaluasi Text Summarization</b>\n",
        "\n",
        "Evaluasi peringkasan teks dilakukan menggunakan metrik ROUGE-1 dengan membandingkan ringkasan sistem terhadap ringkasan referensi.\n",
        "\n",
        "Hasil evaluasi menunjukkan:\n",
        "\n",
        "Precision = 0.714\n",
        "\n",
        "Recall = 0.625\n",
        "\n",
        "Nilai precision yang cukup tinggi menunjukkan bahwa sebagian besar kata pada ringkasan sistem juga terdapat pada ringkasan referensi. Sementara itu, nilai recall yang lebih rendah mengindikasikan bahwa masih terdapat informasi penting dalam ringkasan referensi yang belum sepenuhnya tertangkap oleh sistem.\n",
        "\n",
        "# <b>Kesimpulan</b>\n",
        "\n",
        "Berdasarkan hasil evaluasi, sistem temu kembali informasi yang dibangun telah berfungsi dengan baik. Model Vector Space Model (TF-IDF) menunjukkan performa yang lebih baik dibandingkan Boolean Information Retrieval dalam hal precision, dengan tetap mempertahankan recall maksimal.\n",
        "\n",
        "Pada fitur peringkasan teks, metode ekstraktif berbasis frekuensi kata mampu menghasilkan ringkasan yang cukup representatif terhadap isi dokumen, meskipun masih dapat ditingkatkan dengan metode yang lebih kompleks.\n",
        "\n",
        "Secara keseluruhan, sistem ini layak digunakan sebagai implementasi proyek UAS Sistem Temu Kembali Informasi dan telah memenuhi aspek pencarian, pengelompokan dokumen, peringkasan teks, serta evaluasi performa sesuai dengan ketentuan yang diberikan."
      ],
      "metadata": {
        "id": "QertY8R2nc1m"
      }
    }
  ]
}